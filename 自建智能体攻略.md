





# 本地双3090部署大模型

DeepSeek-R1-0528-Qwen3-8B 这个模型是从 DeepSeek-R1-0528 的思维链蒸馏出来用于后训练 Qwen3 8B Base 而得。通过蒸馏技术，在 AIME 2024 上达到 86.0，超越 Qwen3-8B (+10%)，媲美更大模型！
DeepSeek-R1-0528-Qwen3-8B在 2024 年美国数学邀请赛（AIME）上的开源模型中取得了最先进（SOTA）的性能，比 Qwen3 8B 提高了 10.0%，性能与 Qwen3-235B-thinking 相当。


## 下载模型

模型文件：https://modelscope.cn/models/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B/files
在下载前，先通过如下命令安装 ModelScope
```
pip install modelscope
```
命令行下载完整模型库
```
modelscope download --model deepseek-ai/DeepSeek-R1-0528-Qwen3-8B --local_dir .
```
模型大小约 16GB

## 部署
用 vllm 拉起大模型
```
pip install --upgrade vllm
CUDA_VIDIBLE_DEVICES=0,1 vllm serve . --served-model-name R1-0528-Qwen3-8B --port 3002  --tensor-parallel-size 2
```
